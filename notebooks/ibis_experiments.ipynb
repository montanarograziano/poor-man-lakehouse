{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4f0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graziano/GitHub/poor-man-lakehouse/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "25/09/06 19:12:29 WARN Utils: Your hostname, MacBookPro.homenet.telecomitalia.it resolves to a loopback address: 127.0.0.1; using 192.168.1.81 instead (on interface en0)\n",
      "25/09/06 19:12:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/graziano/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/graziano/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.13 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.13 added as a dependency\n",
      "org.apache.iceberg#iceberg-aws-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-568729c9-11c6-4a9e-b90d-39f27eba66d3;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/homebrew/Cellar/apache-spark/3.5.6/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.13;1.9.2 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.13;0.103.3 in central\n",
      "\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central\n",
      ":: resolution report :: resolve 79ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.13;1.9.2 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.13;0.103.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-568729c9-11c6-4a9e-b90d-39f27eba66d3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "25/09/06 19:12:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\u001b[32m2025-09-06 19:12:32.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpoor_man_lakehouse.dremio.builder\u001b[0m:\u001b[36m_initialize_dremio\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mInitializing Dremio setup...\u001b[0m\n",
      "\u001b[32m2025-09-06 19:12:32.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpoor_man_lakehouse.dremio.builder\u001b[0m:\u001b[36m_initialize_dremio\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mAdmin user authentication successful\u001b[0m\n",
      "\u001b[32m2025-09-06 19:12:33.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpoor_man_lakehouse.dremio.builder\u001b[0m:\u001b[36m_ensure_nessie_catalog\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mNessie catalog 'nessie' already exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from poor_man_lakehouse import DremioConnection\n",
    "from poor_man_lakehouse import IbisConnection\n",
    "\n",
    "d = DremioConnection()\n",
    "\n",
    "conn = IbisConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdcfac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[us, UTC]",
         "type": "unknown"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ask",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "details",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "16c7677a-71a5-4371-9cc4-dc3d7618bf8d",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00+00:00",
         "AAPL",
         "150.0",
         "151.0",
         "[{'key': 'created_by', 'value': 'user1'}]"
        ],
        [
         "1",
         "2023-01-02 11:00:00+00:00",
         "GOOGL",
         "2800.0",
         "2805.0",
         "[{'key': 'created_by', 'value': 'user2'}]"
        ],
        [
         "2",
         "2023-01-03 11:00:00+00:00",
         "MSFT",
         "300.0",
         "305.0",
         "[{'key': 'created_by', 'value': None}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': 'user1'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 11:00:00+00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': 'user2'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 11:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>300.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': None}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime symbol     bid     ask  \\\n",
       "0 2023-01-01 11:00:00+00:00   AAPL   150.0   151.0   \n",
       "1 2023-01-02 11:00:00+00:00  GOOGL  2800.0  2805.0   \n",
       "2 2023-01-03 11:00:00+00:00   MSFT   300.0   305.0   \n",
       "\n",
       "                                     details  \n",
       "0  [{'key': 'created_by', 'value': 'user1'}]  \n",
       "1  [{'key': 'created_by', 'value': 'user2'}]  \n",
       "2     [{'key': 'created_by', 'value': None}]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polars_table = conn.read_table(\"default\", \"prova\", \"polars\")\n",
    "polars_table.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17150d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graziano/GitHub/poor-man-lakehouse/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ask",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "details",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "581b099a-de07-4e6a-af4b-f10bb1fc121f",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00",
         "AAPL",
         "150.0",
         "151.0",
         "{'created_by': 'user1'}"
        ],
        [
         "1",
         "2023-01-02 11:00:00",
         "GOOGL",
         "2800.0",
         "2805.0",
         "{'created_by': 'user2'}"
        ],
        [
         "2",
         "2023-01-03 11:00:00",
         "MSFT",
         "300.0",
         "305.0",
         "{'created_by': None}"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>{'created_by': 'user1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 11:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>{'created_by': 'user2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 11:00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>300.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>{'created_by': None}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime symbol     bid     ask                  details\n",
       "0 2023-01-01 11:00:00   AAPL   150.0   151.0  {'created_by': 'user1'}\n",
       "1 2023-01-02 11:00:00  GOOGL  2800.0  2805.0  {'created_by': 'user2'}\n",
       "2 2023-01-03 11:00:00   MSFT   300.0   305.0     {'created_by': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_table = conn.read_table(\"default\", \"prova\", \"pyspark\")\n",
    "pyspark_table.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ad774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graziano/GitHub/poor-man-lakehouse/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "25/09/06 19:14:57 WARN SimpleFunctionRegistry: The function unwrap_json_str replaced a previously registered function.\n",
      "25/09/06 19:14:57 WARN SimpleFunctionRegistry: The function unwrap_json_int replaced a previously registered function.\n",
      "25/09/06 19:14:57 WARN SimpleFunctionRegistry: The function unwrap_json_bool replaced a previously registered function.\n",
      "25/09/06 19:14:57 WARN SimpleFunctionRegistry: The function unwrap_json_float replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "794e4890-610b-42ff-823e-1040c8637164",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00",
         "AAPL"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime symbol\n",
       "0 2023-01-01 11:00:00   AAPL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_table.select(\"datetime\", \"symbol\").filter(\n",
    "    pyspark_table[\"symbol\"] == \"AAPL\"\n",
    ").execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434c985",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "DuckDB read_table is not implemented yet. Use sql() method instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprova\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mduckdb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.execute()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/poor-man-lakehouse/src/poor_man_lakehouse/ibis/builder.py:85\u001b[39m, in \u001b[36mIbisConnection.read_table\u001b[39m\u001b[34m(self, database, table_name, engine)\u001b[39m\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     81\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not read table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatabase\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with Polars: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m         )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mduckdb\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDuckDB read_table is not implemented yet. Use sql() method instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: DuckDB read_table is not implemented yet. Use sql() method instead."
     ]
    }
   ],
   "source": [
    "conn.read_table(\"default\", \"prova\", \"duckdb\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfbf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[us, UTC]",
         "type": "unknown"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "035f3aaf-6e53-45e6-ba13-99fdc21e7af1",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00+00:00",
         "AAPL"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime symbol\n",
       "0 2023-01-01 11:00:00+00:00   AAPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polars_table.select(\"datetime\", \"symbol\").filter(\n",
    "    polars_table[\"symbol\"] == \"AAPL\"\n",
    ").execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poor-man-lakehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
