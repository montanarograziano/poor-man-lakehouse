{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c4f0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyspark tables ['bids', 'prova']\n",
      "Polars tables []\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from poor_man_lakehouse.config import settings\n",
    "from poor_man_lakehouse.spark.builder import retrieve_current_spark_session\n",
    "from pyiceberg.catalog import load_catalog\n",
    "import ibis\n",
    "from ibis import Table\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class IbisConnection:\n",
    "    def __init__(self):\n",
    "        self.connections = {\n",
    "            \"pyspark\": ibis.pyspark.connect(session=retrieve_current_spark_session()),\n",
    "            \"polars\": ibis.polars.connect(),\n",
    "            \"duckdb\": ibis.duckdb.connect(database=\":memory:\", read_only=False),\n",
    "        }\n",
    "        self._catalog_config = settings.ICEBERG_STORAGE_OPTIONS | {\n",
    "            \"type\": \"rest\",\n",
    "            \"uri\": settings.NESSIE_PYICEBERG_SERVER_URI,\n",
    "        }\n",
    "        self.pyiceberg_catalog = load_catalog(\"nessie\", **self._catalog_config)\n",
    "\n",
    "    def get_connection(self, engine: Literal[\"pyspark\", \"polars\", \"duckdb\"]):\n",
    "        if engine not in self.connections:\n",
    "            raise ValueError(f\"Unsupported engine: {engine}\")\n",
    "        return self.connections[engine]\n",
    "\n",
    "    def list_tables(self, engine: Literal[\"pyspark\", \"polars\", \"duckdb\"]):\n",
    "        con = self.get_connection(engine)\n",
    "        return con.list_tables()\n",
    "\n",
    "    def sql(self, engine: Literal[\"pyspark\", \"polars\", \"duckdb\"], query: str):\n",
    "        con = self.get_connection(engine)\n",
    "        return con.sql(query)\n",
    "\n",
    "    def read_table(\n",
    "        self,\n",
    "        database: str,\n",
    "        table_name: str,\n",
    "        engine: Literal[\"pyspark\", \"polars\", \"duckdb\"],\n",
    "    ) -> Table:\n",
    "        \"\"\"\n",
    "        Read an Iceberg table in lazy mode using the specified engine.\n",
    "\n",
    "        Args:\n",
    "            database: The database/namespace name\n",
    "            table_name: The table name\n",
    "            engine: The engine to use for reading (\"pyspark\", \"polars\", \"duckdb\")\n",
    "\n",
    "        Returns:\n",
    "            Lazy Ibis table expression\n",
    "        \"\"\"\n",
    "        con = self.get_connection(engine)\n",
    "\n",
    "        if engine == \"pyspark\":\n",
    "            # For PySpark, first check if table exists in the current context\n",
    "            # Since we're using Nessie catalog and the table is already in the catalog\n",
    "            try:\n",
    "                # Try with just the table name first (since we set the current database)\n",
    "                return con.table(table_name)\n",
    "            except Exception as e:\n",
    "                raise ValueError(\n",
    "                    f\"Could not read table {database}.{table_name} with PySpark: {e}\"\n",
    "                )\n",
    "\n",
    "        elif engine == \"polars\":\n",
    "            # For Polars, we need to use PyIceberg to get the table and then create Ibis table\n",
    "            try:\n",
    "                # Get the table from PyIceberg catalog\n",
    "                iceberg_table = self.pyiceberg_catalog.load_table(\n",
    "                    f\"{database}.{table_name}\"\n",
    "                )\n",
    "                lazyframe = pl.scan_iceberg(iceberg_table, reader_override=\"pyiceberg\")\n",
    "                con.create_table(f\"{database}.{table_name}\", lazyframe)\n",
    "                return con.table(f\"{database}.{table_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                raise ValueError(\n",
    "                    f\"Could not read table {database}.{table_name} with Polars: {e}\"\n",
    "                )\n",
    "\n",
    "        elif engine == \"duckdb\":\n",
    "            raise NotImplementedError(\n",
    "                \"DuckDB read_table is not implemented yet. Use sql() method instead.\"\n",
    "            )\n",
    "\n",
    "\n",
    "conn = IbisConnection()\n",
    "print(\"Pyspark tables\", conn.list_tables(\"pyspark\"))\n",
    "print(\"Polars tables\", conn.list_tables(\"polars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbdcfac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[us, UTC]",
         "type": "unknown"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ask",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "details",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "51cef18b-f3f3-4c6a-b4eb-cbde27456d17",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00+00:00",
         "AAPL",
         "150.0",
         "151.0",
         "[{'key': 'created_by', 'value': 'user1'}]"
        ],
        [
         "1",
         "2023-01-02 11:00:00+00:00",
         "GOOGL",
         "2800.0",
         "2805.0",
         "[{'key': 'created_by', 'value': 'user2'}]"
        ],
        [
         "2",
         "2023-01-03 11:00:00+00:00",
         "MSFT",
         "300.0",
         "305.0",
         "[{'key': 'created_by', 'value': None}]"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': 'user1'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 11:00:00+00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': 'user2'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 11:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>300.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>[{'key': 'created_by', 'value': None}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime symbol     bid     ask  \\\n",
       "0 2023-01-01 11:00:00+00:00   AAPL   150.0   151.0   \n",
       "1 2023-01-02 11:00:00+00:00  GOOGL  2800.0  2805.0   \n",
       "2 2023-01-03 11:00:00+00:00   MSFT   300.0   305.0   \n",
       "\n",
       "                                     details  \n",
       "0  [{'key': 'created_by', 'value': 'user1'}]  \n",
       "1  [{'key': 'created_by', 'value': 'user2'}]  \n",
       "2     [{'key': 'created_by', 'value': None}]  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.read_table(\"default\", \"prova\", \"polars\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d17150d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graziano/GitHub/poor-man-lakehouse/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "25/09/06 19:03:55 WARN SimpleFunctionRegistry: The function unwrap_json_str replaced a previously registered function.\n",
      "25/09/06 19:03:55 WARN SimpleFunctionRegistry: The function unwrap_json_int replaced a previously registered function.\n",
      "25/09/06 19:03:55 WARN SimpleFunctionRegistry: The function unwrap_json_bool replaced a previously registered function.\n",
      "25/09/06 19:03:55 WARN SimpleFunctionRegistry: The function unwrap_json_float replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "symbol",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ask",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "details",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "5b334b2c-03ca-4037-882b-08c88e685c31",
       "rows": [
        [
         "0",
         "2023-01-01 11:00:00",
         "AAPL",
         "150.0",
         "151.0",
         "{'created_by': 'user1'}"
        ],
        [
         "1",
         "2023-01-02 11:00:00",
         "GOOGL",
         "2800.0",
         "2805.0",
         "{'created_by': 'user2'}"
        ],
        [
         "2",
         "2023-01-03 11:00:00",
         "MSFT",
         "300.0",
         "305.0",
         "{'created_by': None}"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>{'created_by': 'user1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 11:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>{'created_by': 'user2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 11:00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>300.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>{'created_by': None}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime symbol     bid     ask                  details\n",
       "0 2023-01-01 11:00:00   AAPL   150.0   151.0  {'created_by': 'user1'}\n",
       "1 2023-01-02 11:00:00  GOOGL  2800.0  2805.0  {'created_by': 'user2'}\n",
       "2 2023-01-03 11:00:00   MSFT   300.0   305.0     {'created_by': None}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.read_table(\"default\", \"prova\", \"pyspark\").execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poor-man-lakehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
