{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea60e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poor_man_lakehouse.spark.builder import retrieve_current_spark_session\n",
    "from poor_man_lakehouse.config import settings\n",
    "\n",
    "spark = retrieve_current_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31997cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()\n",
    "spark.sql(f\"show schemas in {settings.CATALOG}\").show()\n",
    "spark.sql(\"show schemas in spark_catalog\").show()\n",
    "spark.sql(f\"SHOW  tables in {settings.CATALOG}.default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import datetime\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "data = pl.DataFrame(\n",
    "    {\n",
    "        \"datetime\": [\n",
    "            datetime.datetime(2023, 1, 1, 12, 0),\n",
    "            datetime.datetime(2023, 1, 2, 12, 0),\n",
    "            datetime.datetime(2023, 1, 3, 12, 0),\n",
    "        ],\n",
    "        \"symbol\": [\"AAPL\", \"GOOGL\", \"MSFT\"],\n",
    "        \"bid\": [150.0, 2800.0, 300.0],\n",
    "        \"ask\": [151.0, 2805.0, 305.0],\n",
    "        \"details\": [\n",
    "            {\"created_by\": \"user1\"},\n",
    "            {\"created_by\": \"user2\"},\n",
    "            {\"created_by\": None},\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "spark_df: DataFrame = spark.createDataFrame(data.to_pandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\n",
    "    f\"{settings.CATALOG}.default.prova\", mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"SELECT * FROM {settings.CATALOG}.default.prova\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc070cc",
   "metadata": {},
   "source": [
    "## Testing LakeSail\n",
    "\n",
    "To test Lakesail, it's necessary to restart the kernel since the sparkSession was already created and we need a clean one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86483ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysail.spark import SparkConnectServer\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "server = SparkConnectServer()\n",
    "server.start()\n",
    "address = server.listening_address\n",
    "if address is None:\n",
    "    raise RuntimeError(\"Failed to start Spark Connect server\")\n",
    "_, port = address\n",
    "\n",
    "spark = SparkSession.builder.remote(f\"sc://localhost:{port}\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918bceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3a://warehouse/test_parquet\"\n",
    "df = spark.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], schema=\"id INT, name STRING\")\n",
    "df.write.parquet(path)\n",
    "\n",
    "df = spark.read.parquet(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poor-man-lakehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
