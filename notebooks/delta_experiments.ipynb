{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c090d6",
   "metadata": {},
   "source": [
    "# Delta experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774a558",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from deltalake import DeltaTable, write_deltalake\n",
    "from poor_man_lakehouse.config import settings\n",
    "\n",
    "delta_path = \"s3://warehouse/default/test_delta\"\n",
    "\n",
    "# Create a mock Polars DataFrame and save it as a Delta. It should have columns date (in yyyy-mm-dd format), country, and value.\n",
    "df = pl.DataFrame({\n",
    "    \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n",
    "    \"country\": [\"US\", \"CA\", \"MX\"],\n",
    "    \"value\": [100, 200, 300],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32beb862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Delta using delta-rs write_deltalake function\n",
    "write_deltalake(\n",
    "    table_or_uri=delta_path,\n",
    "    data=df.to_arrow(),\n",
    "    mode=\"overwrite\",\n",
    "    name=\"test_delta\",\n",
    "    partition_by=[\"date\"],\n",
    "    schema_mode=\"merge\",\n",
    "    storage_options=settings.S3_STORAGE_OPTIONS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTable(\n",
    "    \"s3://warehouse/default/test_delta\",\n",
    "    storage_options={\n",
    "        \"AWS_ACCESS_KEY_ID\": \"minioadmin\",\n",
    "        \"AWS_SECRET_ACCESS_KEY\": \"miniopassword\",\n",
    "        \"AWS_ENDPOINT_URL\": \"http://minio:9000\",\n",
    "        \"AWS_REGION\": \"eu-central-1\",\n",
    "        \"AWS_ALLOW_HTTP\": \"true\",\n",
    "        \"aws_conditional_put\": \"etag\",\n",
    "    },\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c557793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Delta using delta-rs write_deltalake function\n",
    "write_deltalake(\n",
    "    table_or_uri=delta_path,\n",
    "    data=df.to_arrow(),\n",
    "    mode=\"overwrite\",\n",
    "    name=\"test_delta\",\n",
    "    partition_by=[\"date\"],\n",
    "    schema_mode=\"merge\",\n",
    "    storage_options=settings.S3_STORAGE_OPTIONS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd44710",
   "metadata": {},
   "source": [
    "One can also use `write_delta` predicate from Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4029d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_delta(\n",
    "    target=delta_path,\n",
    "    mode=\"overwrite\",\n",
    "    delta_write_options={\n",
    "        \"partition_by\": [\"date\"],\n",
    "        \"schema_mode\": \"merge\",\n",
    "        \"name\": \"test_delta\",\n",
    "    },\n",
    "    storage_options=settings.S3_STORAGE_OPTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd95a6",
   "metadata": {},
   "source": [
    "## Read Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9e746",
   "metadata": {},
   "source": [
    "We can read delta using the `DeltaTable` class, and then converting to Polars through Arrow (but that will load the whole table with no possibility of filtering data), or using `scan_delta` and filter before materializing it.\n",
    "\n",
    "In case the Delta is located in a remote storage, we can pass `storage_options` parameter (to both Polars and DeltaTable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable(delta_path, storage_options=settings.S3_STORAGE_OPTIONS)\n",
    "pl.from_arrow(dt.to_pyarrow_table()).select(\"date\", \"country\", \"value\").sort(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scan_delta(delta_path, storage_options=settings.S3_STORAGE_OPTIONS).collect().select(\n",
    "    \"date\", \"country\", \"value\"\n",
    ").sort(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaa32f",
   "metadata": {},
   "source": [
    "## Read Delta using DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8bbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query the Delta table using DuckDB\n",
    "duckdb.sql(f\"\"\"\n",
    "CREATE SECRET if not exists s3_secret (\n",
    "    TYPE S3,\n",
    "    KEY_ID '{settings.AWS_ACCESS_KEY_ID}',\n",
    "    SECRET '{settings.AWS_SECRET_ACCESS_KEY}',\n",
    "    ENDPOINT 'minio:9000',\n",
    "    REGION '{settings.AWS_DEFAULT_REGION}',\n",
    "    URL_STYLE 'path',\n",
    "    USE_SSL false\n",
    ");\n",
    "            \"\"\")\n",
    "duckdb.sql(f\"\"\"\n",
    "SELECT date, country, value FROM delta_scan('{delta_path}' ORDER BY date)\n",
    "           \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1ca23",
   "metadata": {},
   "source": [
    "## Upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55342520",
   "metadata": {},
   "source": [
    "Create another DataFrame with a 2 rows, one that will be appended and one that will be overwritten (considering `date` as join column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e006ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df = pl.DataFrame({\n",
    "    \"date\": [\"2023-01-01\", \"2023-01-04\"],\n",
    "    \"country\": [\"US\", \"IT\"],\n",
    "    \"value\": [150, 250],\n",
    "})\n",
    "upsert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85056007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert the new data into the Delta table\n",
    "dt.merge(\n",
    "    source=upsert_df.to_arrow(),\n",
    "    source_alias=\"source\",\n",
    "    target_alias=\"target\",\n",
    "    predicate=\"source.date = target.date\",\n",
    "    merge_schema=True,\n",
    ").when_matched_update_all().when_not_matched_insert_all().execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the upsert\n",
    "pl.scan_delta(delta_path, storage_options=settings.S3_STORAGE_OPTIONS).collect().select(\n",
    "    \"date\", \"country\", \"value\"\n",
    ").sort(\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015b5c9",
   "metadata": {},
   "source": [
    "## Read Delta History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.from_dicts(dt.history()).sort(\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94e26f",
   "metadata": {},
   "source": [
    "## Perform Time Travel, Vacuum and Optimize\n",
    "\n",
    "Delta has some nice features:\n",
    "\n",
    "- **Time travel**: Restore old version\n",
    "- **Vacuum**: Remove data not referenced by available table version\n",
    "- **Optimize**: Compact smaller files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31330290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial version from Polars\n",
    "pl.scan_delta(\n",
    "    delta_path, version=0, storage_options=settings.S3_STORAGE_OPTIONS\n",
    ").collect().select(\"date\", \"country\", \"value\").sort(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d88481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore initial version\n",
    "dt.restore(target=0)\n",
    "pl.scan_delta(delta_path, storage_options=settings.S3_STORAGE_OPTIONS).collect().select(\n",
    "    \"date\", \"country\", \"value\"\n",
    ").sort(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155e396",
   "metadata": {},
   "source": [
    "However, restoring a Delta causes DuckDB to break on read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ceb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Query the Delta table using DuckDB\n",
    "duckdb.sql(f\"\"\"\n",
    "SELECT * FROM delta_scan('{delta_path}')\n",
    "           \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore latest version\n",
    "print(dt.restore(target=1))\n",
    "# Verify the restored version\n",
    "pl.scan_delta(delta_path, storage_options=settings.S3_STORAGE_OPTIONS).collect().select(\n",
    "    \"date\", \"country\", \"value\"\n",
    ").sort(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1e8a7",
   "metadata": {},
   "source": [
    "The following command will remove all files that are not referenced by Delta versions in history. It will output a list of deleted files, that are not restorable.\n",
    "\n",
    "A `retention_hours` period can be specified, along with `dry_run`. `enforce_retention_duration` needs to be set at False in case `retention_hours` is lower than the Delta default one, which is 168 hours in case not specified differently at Delta creation with `configs` param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vacuum Delta\n",
    "dt.vacuum(retention_hours=0, dry_run=True, enforce_retention_duration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd423dbe",
   "metadata": {},
   "source": [
    "*Optimize* will compact smaller files (think about small insertion) together, so that queries can be speed up by looking at less files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.optimize.compact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378a13e",
   "metadata": {},
   "source": [
    "## Z-Order\n",
    "\n",
    "Z-Order is a way to reorganize data in storage in order to optimize queries. It allows for more data-skipping by colocating relevant files together. Think about it a smart sorting of files based on one or multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e28323",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.optimize.z_order(columns=[\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f526d9",
   "metadata": {},
   "source": [
    "## Unity Catalog experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "c = pl.Catalog(workspace_url=\"http://localhost:8080\", require_https=False)\n",
    "c.list_catalogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9672770",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.list_tables(catalog_name=\"unity\", namespace=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock dataframe\n",
    "df = pl.DataFrame({\n",
    "    \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n",
    "    \"country\": [\"US\", \"CA\", \"MX\"],\n",
    "    \"value\": [100, 200, 300],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_path = \"s3://warehouse/delta_unity_catalog\"\n",
    "\n",
    "tables = [\n",
    "    table.name for table in c.list_tables(catalog_name=\"unity\", namespace=\"default\")\n",
    "]\n",
    "if \"test_table\" in tables:\n",
    "    c.delete_table(catalog_name=\"unity\", namespace=\"default\", table_name=\"test_table\")\n",
    "c.create_table(\n",
    "    catalog_name=\"unity\",\n",
    "    namespace=\"default\",\n",
    "    table_name=\"test_table\",\n",
    "    schema=df.schema,\n",
    "    table_type=\"EXTERNAL\",\n",
    "    data_source_format=\"DELTA\",\n",
    "    storage_root=delta_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.write_table(\n",
    "    df=df,\n",
    "    catalog_name=\"unity\",\n",
    "    namespace=\"default\",\n",
    "    delta_mode=\"overwrite\",\n",
    "    table_name=\"test_table\",\n",
    "    storage_options=settings.S3_STORAGE_OPTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.scan_table(\n",
    "    catalog_name=\"unity\",\n",
    "    namespace=\"default\",\n",
    "    table_name=\"test_table\",\n",
    "    storage_options=settings.S3_STORAGE_OPTIONS,\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc383a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "duckdb.sql(\"\"\"\n",
    "INSTALL uc_catalog;\n",
    "INSTALL delta;\n",
    "LOAD delta;\n",
    "LOAD uc_catalog;\n",
    "CREATE OR REPLACE SECRET uc_secret (\n",
    "\tTYPE UC,\n",
    "\tENDPOINT 'http://127.0.0.1:8080',\n",
    "    TOKEN 'not used',\n",
    "    AWS_REGION 'eu-central-1'\n",
    "\n",
    ");\n",
    "ATTACH IF NOT EXISTS 'unity' AS test_catalog (TYPE UC_CATALOG, SECRET uc_secret);\n",
    "SHOW ALL TABLES;\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poor-man-lakehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
